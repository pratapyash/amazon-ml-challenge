{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from src.constants import entity_unit_map\n",
    "import ast\n",
    "\n",
    "# Define constants\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "TRAIN_IMAGES_DIR = 'train_images'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Custom dataset\n",
    "class ProductImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.entity_names = sorted(self.data['entity_name'].unique())\n",
    "        self.entity_name_to_idx = {name: idx for idx, name in enumerate(self.entity_names)}\n",
    "        self.entity_units = {entity: sorted(units) for entity, units in entity_unit_map.items()}\n",
    "        self.max_units = max(len(units) for units in self.entity_units.values())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.basename(self.data.iloc[idx]['image_link'])\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        entity_name = self.data.iloc[idx]['entity_name']\n",
    "        entity_value, entity_unit = self.parse_entity_value(self.data.iloc[idx]['entity_value'])\n",
    "        \n",
    "        entity_name_tensor = torch.zeros(len(self.entity_names), dtype=torch.float32)\n",
    "        entity_name_tensor[self.entity_name_to_idx[entity_name]] = 1\n",
    "        \n",
    "        entity_unit_tensor = torch.zeros(self.max_units, dtype=torch.float32)\n",
    "        if entity_name in self.entity_units and entity_unit in self.entity_units[entity_name]:\n",
    "            unit_idx = self.entity_units[entity_name].index(entity_unit)\n",
    "            entity_unit_tensor[unit_idx] = 1\n",
    "        \n",
    "        return img, entity_name_tensor, torch.tensor(entity_value, dtype=torch.float32), entity_unit_tensor, entity_name\n",
    "\n",
    "    def parse_entity_value(self, value_str):\n",
    "        try:\n",
    "            value, unit = value_str.rsplit(' ', 1)\n",
    "            if unit == 'fluid':\n",
    "                value, unit = value_str.rsplit(' ', 2)[0], ' '.join(value_str.rsplit(' ', 2)[1:])\n",
    "            return float(value), unit\n",
    "        except ValueError:\n",
    "            try:\n",
    "                value_list = ast.literal_eval(value_str)\n",
    "                if isinstance(value_list, list) and len(value_list) == 2:\n",
    "                    return sum(value_list) / 2, 'unknown'\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        return 0.0, 'unknown'\n",
    "\n",
    "# Data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load data\n",
    "train_dataset = ProductImageDataset('dataset/train.csv', TRAIN_IMAGES_DIR, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "# Custom model\n",
    "class ProductImageModel(nn.Module):\n",
    "    def __init__(self, num_entity_names, max_units):\n",
    "        super(ProductImageModel, self).__init__()\n",
    "        self.resnet = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V1)\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        \n",
    "        self.fc_entity_name = nn.Linear(num_ftrs, num_entity_names).float()\n",
    "        self.fc_entity_value = nn.Linear(num_ftrs, 1).float()\n",
    "        self.fc_entity_units = nn.Linear(num_ftrs, max_units).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.resnet(x)\n",
    "        entity_name_out = self.fc_entity_name(features)\n",
    "        entity_value_out = self.fc_entity_value(features).squeeze(1)\n",
    "        entity_units_out = self.fc_entity_units(features)\n",
    "        return entity_name_out, entity_value_out, entity_units_out\n",
    "\n",
    "# Initialize model\n",
    "model = ProductImageModel(len(train_dataset.entity_names), train_dataset.max_units)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion_classification = nn.BCEWithLogitsLoss()\n",
    "criterion_regression = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
    "    \n",
    "    for images, entity_names, entity_values, entity_units, entity_name_str in progress_bar:\n",
    "        images = images.to(DEVICE).float()\n",
    "        entity_names = entity_names.to(DEVICE).float()\n",
    "        entity_values = entity_values.to(DEVICE).float()\n",
    "        entity_units = entity_units.to(DEVICE).float()\n",
    "        \n",
    "        # Forward pass\n",
    "        entity_name_out, entity_value_out, entity_units_out = model(images)\n",
    "        \n",
    "        # Compute losses\n",
    "        loss_entity_name = criterion_classification(entity_name_out, entity_names)\n",
    "        loss_entity_value = criterion_regression(entity_value_out, entity_values)\n",
    "        loss_entity_units = criterion_classification(entity_units_out, entity_units)\n",
    "        \n",
    "        loss = loss_entity_name + loss_entity_value + loss_entity_units\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Average Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "# Save the model\n",
    "torch.save({\n",
    "    'epoch': NUM_EPOCHS,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': avg_loss,\n",
    "}, 'product_image_model.pth')\n",
    "\n",
    "print(\"Training completed. Model saved.\")\n",
    "\n",
    "# Evaluation and prediction function\n",
    "def predict(model, image):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        entity_name_out, entity_value_out, entity_units_out = model(image.unsqueeze(0).to(DEVICE).float())\n",
    "        \n",
    "        predicted_entity = train_dataset.entity_names[torch.argmax(entity_name_out).item()]\n",
    "        predicted_value = entity_value_out.item()\n",
    "        predicted_unit_idx = torch.argmax(entity_units_out).item()\n",
    "        predicted_unit = train_dataset.entity_units.get(predicted_entity, ['unknown'])[predicted_unit_idx] if predicted_unit_idx < len(train_dataset.entity_units.get(predicted_entity, [])) else 'unknown'\n",
    "        \n",
    "        return predicted_entity, predicted_value, predicted_unit\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for images, _, _, _, entity_name_str in tqdm(train_loader, desc=\"Evaluating\"):\n",
    "        images = images.to(DEVICE).float()\n",
    "        \n",
    "        for i, image in enumerate(images):\n",
    "            predicted_entity, predicted_value, predicted_unit = predict(model, image)\n",
    "            formatted_prediction = f\"{predicted_value:.2f} {predicted_unit}\"\n",
    "            predictions.append(formatted_prediction)\n",
    "            \n",
    "            if predicted_entity == entity_name_str[i]:\n",
    "                correct_predictions += 1\n",
    "            total_samples += 1\n",
    "\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f\"Evaluation Results:\")\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save predictions\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "test_df['prediction'] = predictions[:len(test_df)]  # Ensure we have the correct number of predictions\n",
    "test_df[['index', 'prediction']].to_csv('test_out.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to test_out.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image, ImageFile\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from src.constants import entity_unit_map\n",
    "import ast\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# Allow loading truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Define constants\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "TRAIN_IMAGES_DIR = 'train_images'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ACCUMULATION_STEPS = 2\n",
    "CHECKPOINT_PATH = 'product_image_model_checkpoint.pth'\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_data(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    original_count = len(data)\n",
    "    \n",
    "    def is_valid_sample(row):\n",
    "        try:\n",
    "            value_str = row['entity_value']\n",
    "            entity_name = row['entity_name']\n",
    "            value, unit = value_str.rsplit(' ', 1)\n",
    "            if unit == 'fluid':\n",
    "                value, unit = value_str.rsplit(' ', 2)[0], ' '.join(value_str.rsplit(' ', 2)[1:])\n",
    "            float(value)  # Check if value can be converted to float\n",
    "            return unit in entity_unit_map.get(entity_name, [])\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    filtered_data = data[data.apply(is_valid_sample, axis=1)]\n",
    "    filtered_count = len(filtered_data)\n",
    "    \n",
    "    print(f\"Original sample count: {original_count}\")\n",
    "    print(f\"Filtered sample count: {filtered_count}\")\n",
    "    print(f\"Removed {original_count - filtered_count} samples ({(original_count - filtered_count) / original_count:.2%})\")\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "# Custom dataset\n",
    "class ProductImageDataset(Dataset):\n",
    "    def __init__(self, data, img_dir, transform=None):\n",
    "        self.data = data\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.entity_names = sorted(self.data['entity_name'].unique())\n",
    "        self.entity_name_to_idx = {name: idx for idx, name in enumerate(self.entity_names)}\n",
    "        self.entity_units = {entity: sorted(units) for entity, units in entity_unit_map.items()}\n",
    "        self.max_units = max(len(units) for units in self.entity_units.values())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.basename(self.data.iloc[idx]['image_link'])\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {str(e)}\")\n",
    "            # Return a blank image in case of error\n",
    "            img = Image.new('RGB', (224, 224), color='black')\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        entity_name = self.data.iloc[idx]['entity_name']\n",
    "        entity_value, entity_unit = self.parse_entity_value(self.data.iloc[idx]['entity_value'])\n",
    "        \n",
    "        entity_name_tensor = torch.zeros(len(self.entity_names), dtype=torch.float32)\n",
    "        entity_name_tensor[self.entity_name_to_idx[entity_name]] = 1\n",
    "        \n",
    "        entity_unit_tensor = torch.zeros(self.max_units, dtype=torch.float32)\n",
    "        unit_idx = self.entity_units[entity_name].index(entity_unit)\n",
    "        entity_unit_tensor[unit_idx] = 1\n",
    "        \n",
    "        return img, entity_name_tensor, torch.tensor(entity_value, dtype=torch.float32), entity_unit_tensor, entity_name\n",
    "\n",
    "    def parse_entity_value(self, value_str):\n",
    "        value, unit = value_str.rsplit(' ', 1)\n",
    "        if unit == 'fluid':\n",
    "            value, unit = value_str.rsplit(' ', 2)[0], ' '.join(value_str.rsplit(' ', 2)[1:])\n",
    "        return float(value), unit\n",
    "\n",
    "# Data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Preprocess and load data\n",
    "filtered_data = preprocess_data('dataset/train.csv')\n",
    "train_dataset = ProductImageDataset(filtered_data, TRAIN_IMAGES_DIR, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Custom model\n",
    "class ProductImageModel(nn.Module):\n",
    "    def __init__(self, num_entity_names, max_units):\n",
    "        super(ProductImageModel, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        \n",
    "        self.fc_entity_name = nn.Linear(num_ftrs, num_entity_names).float()\n",
    "        self.fc_entity_value = nn.Linear(num_ftrs, 1).float()\n",
    "        self.fc_entity_units = nn.Linear(num_ftrs, max_units).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.resnet(x)\n",
    "        entity_name_out = self.fc_entity_name(features)\n",
    "        entity_value_out = self.fc_entity_value(features).squeeze(1)\n",
    "        entity_units_out = self.fc_entity_units(features)\n",
    "        return entity_name_out, entity_value_out, entity_units_out\n",
    "\n",
    "# Initialize model\n",
    "model = ProductImageModel(len(train_dataset.entity_names), train_dataset.max_units)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion_classification = nn.BCEWithLogitsLoss()\n",
    "criterion_regression = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
    "\n",
    "# Initialize the GradScaler for mixed precision training\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Load checkpoint if it exists\n",
    "start_epoch = 0\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    print(f\"Resuming training from epoch {start_epoch}\")\n",
    "else:\n",
    "    print(\"Starting training from scratch\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
    "    \n",
    "    for i, (images, entity_names, entity_values, entity_units, entity_name_str) in enumerate(progress_bar):\n",
    "        images = images.to(DEVICE)\n",
    "        entity_names = entity_names.to(DEVICE)\n",
    "        entity_values = entity_values.to(DEVICE)\n",
    "        entity_units = entity_units.to(DEVICE)\n",
    "        \n",
    "        # Mixed precision training\n",
    "        with autocast():\n",
    "            # Forward pass\n",
    "            entity_name_out, entity_value_out, entity_units_out = model(images)\n",
    "            \n",
    "            # Compute losses\n",
    "            loss_entity_name = criterion_classification(entity_name_out, entity_names)\n",
    "            loss_entity_value = criterion_regression(entity_value_out, entity_values)\n",
    "            loss_entity_units = criterion_classification(entity_units_out, entity_units)\n",
    "            \n",
    "            loss = loss_entity_name + loss_entity_value + loss_entity_units\n",
    "            loss = loss / ACCUMULATION_STEPS  # Normalize the loss\n",
    "\n",
    "        # Backward and optimize\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (i + 1) % ACCUMULATION_STEPS == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item() * ACCUMULATION_STEPS\n",
    "        progress_bar.set_postfix({'loss': loss.item() * ACCUMULATION_STEPS})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Average Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    # Save checkpoint\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "        'loss': avg_loss,\n",
    "    }, CHECKPOINT_PATH)\n",
    "    print(f\"Checkpoint saved at epoch {epoch+1}\")\n",
    "\n",
    "# Save the final model\n",
    "torch.save({\n",
    "    'epoch': NUM_EPOCHS,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': avg_loss,\n",
    "}, 'product_image_model_final.pth')\n",
    "\n",
    "print(\"Training completed. Final model saved.\")\n",
    "\n",
    "# Evaluation and prediction function\n",
    "@torch.no_grad()\n",
    "def predict(model, image):\n",
    "    model.eval()\n",
    "    with autocast():\n",
    "        entity_name_out, entity_value_out, entity_units_out = model(image.unsqueeze(0).to(DEVICE))\n",
    "        \n",
    "        predicted_entity = train_dataset.entity_names[torch.argmax(entity_name_out).item()]\n",
    "        predicted_value = entity_value_out.item()\n",
    "        predicted_unit_idx = torch.argmax(entity_units_out).item()\n",
    "        predicted_unit = train_dataset.entity_units[predicted_entity][predicted_unit_idx] if predicted_unit_idx < len(train_dataset.entity_units[predicted_entity]) else 'unknown'\n",
    "        \n",
    "        return predicted_entity, predicted_value, predicted_unit\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for images, _, _, _, entity_name_str in tqdm(train_loader, desc=\"Evaluating\"):\n",
    "        images = images.to(DEVICE)\n",
    "        \n",
    "        for i, image in enumerate(images):\n",
    "            predicted_entity, predicted_value, predicted_unit = predict(model, image)\n",
    "            formatted_prediction = f\"{predicted_value:.2f} {predicted_unit}\"\n",
    "            predictions.append(formatted_prediction)\n",
    "            \n",
    "            if predicted_entity == entity_name_str[i]:\n",
    "                correct_predictions += 1\n",
    "            total_samples += 1\n",
    "\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f\"Evaluation Results:\")\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save predictions\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "test_df['prediction'] = predictions[:len(test_df)]  # Ensure we have the correct number of predictions\n",
    "test_df[['index', 'prediction']].to_csv('test_out.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to test_out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
